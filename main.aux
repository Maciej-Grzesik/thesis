\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{malczewska2011}
\citation{american2013diagnostic}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Wprowadzenie}{7}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:intro}{{1}{7}{Wprowadzenie}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motywacja}{7}{section.1.1}\protected@file@percent }
\@writefile{brf}{\backcite{malczewska2011}{{7}{1.1}{section.1.1}}}
\@writefile{brf}{\backcite{american2013diagnostic}{{7}{1.1}{section.1.1}}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Cel}{8}{section.1.2}\protected@file@percent }
\newlabel{sec:aim}{{1.2}{8}{Cel}{section.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Zakres}{8}{section.1.3}\protected@file@percent }
\newlabel{sec:scope}{{1.3}{8}{Zakres}{section.1.3}{}}
\citation{vaswani2023attentionneed}
\citation{mamczur2020}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Teoria}{9}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{brf}{\backcite{vaswani2023attentionneed}{{9}{2}{chapter.2}}}
\@writefile{brf}{\backcite{mamczur2020}{{9}{2}{chapter.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Przepływ informacji wejściowych w rekurencyjnych sieciach neuronowych}}{9}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:rnn_schema}{{2.1}{9}{Przepływ informacji wejściowych w rekurencyjnych sieciach neuronowych}{figure.caption.2}{}}
\citation{jm3}
\citation{DBLP:journals/corr/abs-2010-11929}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Przepływ informacji wejściowych w transformerach}}{10}{figure.caption.3}\protected@file@percent }
\newlabel{fig:transformer_schema}{{2.2}{10}{Przepływ informacji wejściowych w transformerach}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Architektura}{10}{section.2.1}\protected@file@percent }
\@writefile{brf}{\backcite{jm3}{{10}{2.1}{section.2.1}}}
\@writefile{brf}{\backcite{DBLP:journals/corr/abs-2010-11929}{{10}{2.1}{section.2.1}}}
\citation{vaswani2023attentionneed}
\@writefile{brf}{\backcite{vaswani2023attentionneed}{{12}{2.1}{section.2.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Schemat blokowy architektury transformera}}{12}{figure.caption.4}\protected@file@percent }
\newlabel{fig:transformer_architecture}{{2.3}{12}{Schemat blokowy architektury transformera}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Zasada działania}{12}{section.2.2}\protected@file@percent }
\bibstyle{unsrt}
\bibdata{refs}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Scaled dot-product}{13}{subsection.2.2.1}\protected@file@percent }
\newlabel{eq:attention}{{2.1}{13}{Scaled dot-product}{equation.2.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Multi-Head Attention}{13}{subsection.2.2.2}\protected@file@percent }
\newlabel{eq:multiheadattention}{{2.2}{13}{Multi-Head Attention}{equation.2.2.2}{}}
\bibcite{malczewska2011}{1}
\bibcite{american2013diagnostic}{2}
\bibcite{vaswani2023attentionneed}{3}
\bibcite{mamczur2020}{4}
\bibcite{jm3}{5}
\bibcite{DBLP:journals/corr/abs-2010-11929}{6}
\@writefile{toc}{\contentsline {chapter}{Bibliografia}{15}{chapter*.5}\protected@file@percent }
\gdef \@abspage@last{15}
